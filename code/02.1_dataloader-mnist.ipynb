{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Deep Learning Summer School 2019](http://2019.dl-lab.eu) in Gdansk, Poland  \n",
    "**Ordinal Regression Tutorial** by [Sebastian Raschka](https://sebastianraschka.com)  \n",
    "GitHub Repository: https://github.com/rasbt/DL-Gdansk2019-tutorial  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02.1 -- Learning How to Implement a Custom Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Look at the Built-In MNIST DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### MNIST DATASET\n",
    "##########################\n",
    "\n",
    "train_indices = torch.arange(0, 59000)\n",
    "valid_indices = torch.arange(59000, 60000)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "\n",
    "\n",
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "valid_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=False)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          sampler=train_sampler)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          sampler=valid_sampler)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=1,\n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 0, 6, 6, 7, 6, 4, 6, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Check that validation splits are not all from 1 class\n",
    "\n",
    "for images, labels in valid_loader:  \n",
    "    pass\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Custom DataLoader (assuming MNIST is your \"own\" dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustration of how we can efficiently iterate through custom (image) datasets. For this, suppose \n",
    "- mnist_train, mnist_valid, and mnist_test are image folders you created with your own custom images\n",
    "- mnist_train.csv, mnist_valid.csv, and mnist_test.csv are tables that store the image names with their associated class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Inspecting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = Image.open('02_dataloader_files/mnist_train/1.png')\n",
    "plt.imshow(im, cmap='binary');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Dimensions (28, 28)\n",
      "\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1  18  38 136 227 255\n",
      "  254 132   0  90 136  98   3   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  82 156 253 253 253 253 253\n",
      "  253 249 154 219 253 253  35   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  40 150 244 253 253 253 253 253 253\n",
      "  253 253 253 253 253 253  35   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  74 237 253 253 253 253 253 203 182 242\n",
      "  253 253 253 253 253 230  25   0   0   0]\n",
      " [  0   0   0   0   0   0   0  13 200 253 253 253 168 164  91  14  64 246\n",
      "  253 253 253 195  79  32   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  21 219 253 253 159   2   0   0 103 233 253\n",
      "  253 253 177  10   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 171 253 253 147   0   1 155 250 253 253\n",
      "  251 126   5   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 101 236 253 206  32 152 253 253 253 253\n",
      "  130   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  91 253 253 253 253 253 253 241 113\n",
      "    9   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  91 243 253 253 253 253 239  81   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 207 253 253 253 253 158   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 207 253 253 253 253 121   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  24 145 249 253 253 253 253 194   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  59 253 253 253 253 253 253 224  30   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   5 181 253 253 241 114 240 253 253 136   5\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  36 253 253 253 125   0  65 253 253 253  41\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  67 253 253 253  29   2 138 253 253 253  41\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  60 253 253 253 207 202 253 253 253 192   9\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   5 183 253 253 253 253 253 253 230  52   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  62 253 253 253 253 242 116  13   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "im_array = np.array(im)\n",
    "print('Array Dimensions', im_array.shape)\n",
    "print()\n",
    "print(im_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Label File Name\n",
       "0            5     0.png\n",
       "1            8     1.png\n",
       "2            8     2.png\n",
       "3            0     3.png\n",
       "4            9     4.png"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('02_dataloader_files/mnist_train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>512.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>513.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>514.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>515.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>516.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Label File Name\n",
       "0            4   512.png\n",
       "1            0   513.png\n",
       "2            6   514.png\n",
       "3            8   515.png\n",
       "4            4   516.png"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('02_dataloader_files/mnist_test.csv')\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Creating a Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = df['File Name']\n",
    "        self.y = df['Class Label']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Creating Custom DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_indices = torch.arange(0, 150).numpy()\n",
    "valid_indices = torch.arange(150, 256).numpy()\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "\n",
    "\n",
    "# Note that transforms.ToTensor()\n",
    "# already divides pixels by 255. internally\n",
    "\n",
    "custom_transform = transforms.Compose([#transforms.Lambda(lambda x: x/255.), # not necessary\n",
    "                                       transforms.ToTensor()\n",
    "                                      ])\n",
    "\n",
    "train_dataset = MyDataset(csv_path='02_dataloader_files/mnist_train.csv',\n",
    "                          img_dir='02_dataloader_files/mnist_train',\n",
    "                          transform=custom_transform)\n",
    "\n",
    "test_dataset = MyDataset(csv_path='02_dataloader_files/mnist_test.csv',\n",
    "                          img_dir='02_dataloader_files/mnist_test',\n",
    "                          transform=custom_transform)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          sampler=train_sampler)\n",
    "\n",
    "valid_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          sampler=valid_sampler)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=4,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([106, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([106])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "for images, labels in valid_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "for images, labels in test_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Iterating through the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell shows a code block that we would typically use for training a model in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
      "Epoch: 1 | Batch index: 1 | Batch size: 22\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 128\n",
      "Epoch: 2 | Batch index: 1 | Batch size: 22\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape) # note that PyTorch uses NCHW format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 784])\n"
     ]
    }
   ],
   "source": [
    "x_image_as_vector = x.view(-1, 28*28)\n",
    "print(x_image_as_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note that we cannot directly plot gpu tensors via\n",
    "# matplotlib, hence the .cpu() call\n",
    "plt.imshow(x[-1, 0, :, :].cpu(), cmap='binary');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
