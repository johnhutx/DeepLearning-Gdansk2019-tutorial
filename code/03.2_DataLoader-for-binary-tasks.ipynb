{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Deep Learning Summer School 2019](http://2019.dl-lab.eu) in Gdansk, Poland  \n",
    "Ordinal Regression Tutorial by [Sebastian Raschka](https://sebastianraschka.com)  \n",
    "GitHub Repository: https://github.com/rasbt/DL-Gdasnk2019-tutorial  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.6.8\n",
      "IPython 7.2.0\n",
      "\n",
      "torch 1.1.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying the UTKFace DataLoader for Extended Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Previous Custom Dataset Class for Cross-Entropy Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class UTKDatasetAge(Dataset):\n",
    "    \"\"\"Custom Dataset for loading UTKFace images\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.df = df\n",
    "        self.y = df['age'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.df.iloc[index]['filename']))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.y[index]\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Modfied DatasetLoader for Extended Binary Classification for Ordinal Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UTKDatasetAgeBinary(Dataset):\n",
    "    \"\"\"Custom Dataset for loading UTKFace images\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, num_classes, transform=None):\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.df = df\n",
    "        self.y = df['age'].values\n",
    "        self.transform = transform\n",
    "\n",
    "        ###################################\n",
    "        # New:\n",
    "        self.num_classes = num_classes\n",
    "        ###################################\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.df.iloc[index]['filename']))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.y[index]\n",
    "\n",
    "        #############################################################################\n",
    "        ##########################################\n",
    "        ## EXERCISE: Complete the following lines of code\n",
    "        ##########################################\n",
    "        \n",
    "        levels = [1]*label + [0]*( ### ??? \n",
    "        levels = torch.tensor(levels, dtype=torch.float32)\n",
    "        #############################################################################\n",
    "\n",
    "        return img, label, levels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_PATH = 'training_set.csv'\n",
    "TEST_CSV_PATH = 'test_set.csv'\n",
    "IMAGE_PATH = 'UTKFace'\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "NUM_CLASSES = np.unique(df_train['age'].values).shape[0]\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = torch.arange(0, df_train.shape[0]-1000).numpy()\n",
    "valid_indices = torch.arange(df_train.shape[0]-1000, df_train.shape[0]).numpy()\n",
    "del df_train\n",
    "\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                      transforms.RandomCrop((120, 120)),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                     transforms.CenterCrop((120, 120)),\n",
    "                                     transforms.ToTensor()])\n",
    "\n",
    "\n",
    "train_dataset = UTKDatasetAgeBinary(csv_path=TRAIN_CSV_PATH,\n",
    "                                    img_dir=IMAGE_PATH,\n",
    "                                    num_classes=NUM_CLASSES,\n",
    "                                    transform=train_transform)\n",
    "\n",
    "valid_dataset = UTKDatasetAgeBinary(csv_path=TRAIN_CSV_PATH,\n",
    "                                    img_dir=IMAGE_PATH,\n",
    "                                    num_classes=NUM_CLASSES,\n",
    "                                    transform=test_transform)\n",
    "\n",
    "test_dataset = UTKDatasetAgeBinary(csv_path=TEST_CSV_PATH,\n",
    "                                   img_dir=IMAGE_PATH,\n",
    "                                   num_classes=NUM_CLASSES,\n",
    "                                   transform=test_transform)\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=8,\n",
    "                          sampler=train_sampler)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=8,\n",
    "                          sampler=valid_sampler)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=8,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([256, 3, 120, 120])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Ext. binary dimensions: torch.Size([256, 39])\n",
      "Image batch dimensions: torch.Size([256, 3, 120, 120])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Ext. binary dimensions: torch.Size([256, 39])\n",
      "Image batch dimensions: torch.Size([256, 3, 120, 120])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Ext. binary dimensions: torch.Size([256, 39])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "for images, labels, levels in test_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Ext. binary dimensions:', levels.shape)\n",
    "    break\n",
    "    \n",
    "for images, labels, levels in valid_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Ext. binary dimensions:', levels.shape)\n",
    "    break\n",
    "    \n",
    "for images, labels,levels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Ext. binary dimensions:', levels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through the Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 256\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 256\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (features, labels, levels) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', labels.size()[0])\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        levels = levels.to(DEVICE)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      " tensor([19,  3, 39,  7,  2, 29,  5, 29, 20, 24, 18, 30,  2, 24,  6, 35,  9,  4,\n",
      "        34,  7, 20, 14,  7, 19, 20,  3, 28,  5, 33, 33,  4,  4, 11,  3,  4,  4,\n",
      "         6, 30,  5, 25,  0,  2,  6,  5, 35, 15, 29, 14,  7,  1,  5,  3, 14,  3,\n",
      "         7,  3,  4,  3,  9,  5, 39,  2, 39, 31,  7,  5, 39,  5, 24,  6,  8, 13,\n",
      "        17, 14,  8,  2, 19,  4,  5, 14,  5,  5,  5, 10, 30, 24,  4, 29, 29,  5,\n",
      "         1,  3,  7,  6, 19, 31, 10,  1,  2, 13,  9,  9, 13,  0, 19, 13,  4,  5,\n",
      "        39, 13, 34, 26,  7, 15, 24, 11, 12,  8, 19, 23,  5,  7,  1, 11,  3,  5,\n",
      "        28, 21, 10,  2,  0, 15, 24, 13, 13,  0,  5,  6,  7,  6,  2,  5, 29, 31,\n",
      "         2,  5, 35, 37, 17, 13, 17,  5,  7,  5,  5,  3,  5,  5, 10,  9, 11, 14,\n",
      "        16,  1,  8,  7, 27,  5,  5, 24,  3,  6,  4,  7, 14,  9, 39,  4, 30,  5,\n",
      "        31, 13,  5, 18, 28, 10, 11, 14, 17, 15, 15,  9,  1,  1, 36, 34,  6, 13,\n",
      "        19,  3,  7, 11, 12, 15, 11, 39,  7, 31,  7,  8,  1, 11, 14, 10, 19, 19,\n",
      "         5, 25, 17, 35, 13, 15,  5, 16,  9,  8,  5, 29, 34, 19,  5,  4,  7, 14,\n",
      "         0, 19,  9, 35, 17,  5,  1, 28, 31, 34,  0, 37, 14,  5,  1, 39,  4, 18,\n",
      "         5, 29, 24,  6], device='cuda:0')\n",
      "\n",
      "\n",
      "Levels:\n",
      " tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Labels:\\n {labels}\\n\\n')\n",
    "print(f'Levels:\\n {levels}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Loss for Random Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.725887222397812"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0.5) * 40"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
